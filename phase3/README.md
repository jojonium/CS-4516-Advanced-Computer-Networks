CS 4516: Advanced Computer Networks, Phase 3
============================================

Cole Granof and Joseph Petitti

To run this program, run `./classifyFlows filename.pcap`, where `filename.pcap`
is a PCAP packet capture trace. It will identify all flows in this trace and
attempt to identify which application they are from. At the end it will print
summary statistics including the percentage identified as each app.

Python Packages
---------------

We used Python 3 for this phase. Required packages:

* scipy
* kamene
* scikit-learn
* numpy
* pickle

Classification Vectors
----------------------

Our classification model is a random forest classifier generated by creating
feature vectors from test flows with the following information:

* Byte ratio (bytes sent / bytes received, or reciprocal)
* Packet ratio (packets sent / packets received, or reciprocal)
* Mean packet length
* Standard deviation of packet lengths (zero if n <= 2)
* Packet length kurtosis
* Packet length skew
* Mean time gap between each packet (zero if n <= 1)
* Time gap kurtosis
* Time gap skew
* Min packet length
* Max packet length
* Min time gap
* Max time gap
* Protocol (1 for TCP, 0 for UDP)

File Breakdown
--------------

`pcapper.py` runs on TinyCore, captures packets from eth1 and writes them as
PCAP files. `trainer.py` builds the classification model based on feature
vectors that we collected. It takes in two or more pickled python objects
representing the feature vectors and uses them to build the model. It will
continue to train an existing `model.pkl` file if one exists, or will create one
otherwise. `classifyFlows` requires `model.pkl` to be in the same directory. It
takes in a PCAP file as an argument and classifies each of the flows in it based
on the `model.pkl`. It then makes a prediction about what application the flow
came from and prints it in the following format:

```
<timestamp> <src addr> <dst addr> <src port> <dst port> <proto>\
<#packets sent> <#packets rcvd> <#bytes send> <#bytes rcvd> <label>
```

A modified version of `classifyFlows` was also used to build vectors out of PCAP
files to feed to `trainer.py`.

We didn't include the PCAP and feature vector files we used for testing and
training to conserve space and fit within Canvas's upload limit.

Results
-------

The following table shows the results of our test. The second column shows the
percentage of flows that were correctly identified, excluding flows identified
as unknown.

| Application Name | % Correct  | % Unknown  |
| ---------------- | ---------- | ---------- |
| YouTube          | 79.94%     | 11.39%     |
| Browser          | 20.53%     | 34.48%     |
| Google News      | 36.13%     | 24.44%     |
| Fruit Ninja      | 53.33%     | 11.76%     |
| Weather Channel  | 55.84%     | 20.10%     |
| __Average__      | __55.84%__ | __20.10%__ |

For each application, our model was more accurate than simply guessing (20%).
Overall, it is correct more often that not.

Limitations and Shortcomings
----------------------------

For some reason our model really likes misidentifying flows as being from the
Weather Channel app. We hypothesize that the Weather Channel's app performs a
variety of network applications including video, advertisements, and
asynchronous data requests, which makes it easy to confuse with other apps. Our
machine learning model is also probably not ideal because neither of us have
taken a machine learning class.
